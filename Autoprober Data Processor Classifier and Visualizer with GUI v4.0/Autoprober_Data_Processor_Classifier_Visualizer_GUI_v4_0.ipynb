{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoprober Data Processor, Sensor Classifier & Visualizer GUI - Version 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have any doubt about the code fill free to contact-me at:<br>\n",
    "- daniel.h.c.sousa@tecnico.ulisboa.pt\n",
    "- danielsoussa@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import ceil\n",
    "from tkinter import *\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go \n",
    "from matplotlib.ticker import EngFormatter\n",
    "import os, shutil, glob, re, ast, imp, datetime\n",
    "from tkinter import ttk, filedialog, simpledialog, messagebox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_directories(self):\n",
    "    parent_directory = self.save_directory\n",
    "    smps = self.filesnames\n",
    "    if parent_directory == '':\n",
    "        parent_directory = None\n",
    "    if smps == '':\n",
    "        smps = None\n",
    "    if parent_directory != None and smps == None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No SMP files were selected,'+\\\n",
    "                             ' computations interrupted!')\n",
    "        stop = 1\n",
    "    elif parent_directory == None and smps != None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No Saving Directory was selected,'+\\\n",
    "                             ' computations interrupted!')\n",
    "        stop = 1\n",
    "    elif parent_directory == None and smps == None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No SMP files and Saving Directory were selected,'+\\\n",
    "                             ' computations interrupted!')\n",
    "        stop = 1\n",
    "    elif parent_directory != None and smps != None:\n",
    "        stop = 0\n",
    "    if len(os.listdir(parent_directory)) != 0 and stop == 0:\n",
    "        empty_folder_quest = messagebox.askquestion(title = 'WARNING',\n",
    "                                                    message = 'Saving Directory selected'+\\\n",
    "                                                    ' is not empty, computations MAY BE '+\\\n",
    "                                                    'interrupted if overwriting occours!'+\\\n",
    "                                                    ' Do you wish to continue?',\n",
    "                                                    icon = 'warning')\n",
    "        if empty_folder_quest != 'yes':\n",
    "            stop = 1\n",
    "    return stop\n",
    "\n",
    "def check_directories_predictions(self):\n",
    "    csvs_directory = self.csvs_directory\n",
    "    saving_directory = self.save_directory_predictions\n",
    "    model_directory = self.model\n",
    "    if csvs_directory == '':\n",
    "        csvs_directory = None\n",
    "    if saving_directory == '':\n",
    "        saving_directory = None\n",
    "    if model_directory == '':\n",
    "        model_directory = None\n",
    "        \n",
    "    if saving_directory != None and model_directory != None and csvs_directory == None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No CSVs directory was selected, computations'+\\\n",
    "                             ' interrupted!')\n",
    "        stop = 1\n",
    "    elif saving_directory == None and model_directory != None and csvs_directory != None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No Saving Directory was selected, computations'+\\\n",
    "                             ' interrupted!')\n",
    "        stop = 1\n",
    "    elif saving_directory != None and model_directory == None and csvs_directory != None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No Model was selected, computations interrupted!')\n",
    "        stop = 1     \n",
    "    elif saving_directory == None and model_directory == None and csvs_directory != None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No Saving Directory and Model were selected, '+\\\n",
    "                             'computations interrupted!')\n",
    "        stop = 1\n",
    "    elif saving_directory != None and model_directory == None and csvs_directory == None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No Model and CSVs directory were selected, '+\\\n",
    "                             'computations interrupted!')\n",
    "        stop = 1\n",
    "    elif saving_directory == None and model_directory != None and csvs_directory == None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No Saving Directory and CSVs directory were '+\\\n",
    "                             'selected, computations interrupted!')\n",
    "        stop = 1    \n",
    "    elif saving_directory == None and model_directory == None and csvs_directory == None:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='No CSVs directory, Saving Directory and Model were '+\\\n",
    "                             'selected, computations interrupted!')\n",
    "        stop = 1\n",
    "    elif saving_directory != None and model_directory != None and csvs_directory != None:\n",
    "        stop = 0\n",
    "    if len(os.listdir(saving_directory)) != 0 and stop == 0:\n",
    "        empty_folder_quest = messagebox.askquestion(title = 'WARNING',\n",
    "                                                    message = 'Saving Directory selected is '+\\\n",
    "                                                    'not empty, computations MAY BE interrupted'+\\\n",
    "                                                    ' if overwriting occours! Do you wish to continue?',\n",
    "                                                    icon = 'warning')\n",
    "        if empty_folder_quest != 'yes':\n",
    "            stop = 1\n",
    "            \n",
    "    try:\n",
    "        imp.find_module('keras')\n",
    "        stop = 0\n",
    "    except:\n",
    "        messagebox.showerror(title='ERROR',\n",
    "                             message='Keras is not installed, computations interrupted!')\n",
    "        stop = 1\n",
    "    return stop\n",
    "\n",
    "def process_data(file_name, calib_H, map_index_name = ' Input 3 Value',\n",
    "                 field_current_name = ' Input 1 Value',\n",
    "                 probes_current_name = ' Input 2 Value',\n",
    "                 probes_voltage_name = ' M4 Volt [V]'):\n",
    "    data_smp = pd.read_csv(file_name, sep = ';')\n",
    "    df = data_smp[[map_index_name, field_current_name, probes_current_name, probes_voltage_name]]\n",
    "    df.columns = ['Map Index', 'Field Current [A]', 'Probes Current [A]', 'Probes Voltage [V]']\n",
    "    df.insert(4, 'Resistance [Ω]', df['Probes Voltage [V]']/df['Probes Current [A]'])\n",
    "    df.insert(5, 'Applied Field [Oe]', df['Field Current [A]']*calib_H)\n",
    "    df.insert(6, 'Bias Current [A]', df['Probes Current [A]'])\n",
    "    num_sensors = df['Map Index'].max()\n",
    "    return df, num_sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions - Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_RH(num_sensors, df, saving_name, saving_directory, self):\n",
    "    self.progress_text_inter.set('->Working on R(H).')\n",
    "\n",
    "    os.makedirs(saving_directory + '/R_H_curves/SMP/R_H_' + saving_name)\n",
    "    os.makedirs(saving_directory + '/R_H_curves/SMP/R_H_' + saving_name + '/Data')\n",
    "    self.progress_bar_inter['maximum'] = num_sensors+1\n",
    "    for index in range(num_sensors+1):\n",
    "        self.progress_bar_inter['value'] = index\n",
    "        self.progress_bar_inter.update()\n",
    "        df_prov = df.loc[df['Map Index'] == index]\n",
    "\n",
    "        df_prov.to_csv(saving_directory + '/R_H_curves/SMP/R_H_' + saving_name +\\\n",
    "                       '/Data/map_index_'+ str(index) +'.csv',\n",
    "                       columns = ['Field Current [A]', 'Applied Field [Oe]',\n",
    "                                  'Resistance [Ω]', 'Bias Current [A]'], index = False)\n",
    "        df_prov.plot(kind='scatter', x='Applied Field [Oe]', y='Resistance [Ω]', color='red')\n",
    "        plt.grid()\n",
    "        ax = plt.gca()\n",
    "        plt.ylabel('Resistance '+ r'[$\\Omega$]')\n",
    "        formatter = EngFormatter(places=1, sep='\\N{THIN SPACE}')\n",
    "        ax.yaxis.set_major_formatter(formatter)\n",
    "        ibias = df_prov['Bias Current [A]']\n",
    "        ibias = ibias.to_numpy()\n",
    "        if (ibias[0] == ibias).all():\n",
    "            plt.title('Map Index = ' + str(index) + '\\n' + r'$I_{bias} = $' +\\\n",
    "                      np.format_float_scientific(ibias[0], precision = 3,\n",
    "                                                 trim = '0', exp_digits = 1) + ' [A]')\n",
    "        else:\n",
    "            plt.title('Map Index = ' + str(index))\n",
    "        plt.tick_params(direction='in', top=True, right=True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(saving_directory + '/R_H_curves/SMP/R_H_' + saving_name +\\\n",
    "                    '/map_index_'+ str(index) +'.png')\n",
    "        plt.close()\n",
    "    self.progress_bar_inter['value'] = 0\n",
    "    self.progress_bar_inter.update()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_MR(num_sensors, df, saving_name, saving_directory, self, write_xslx = 1,\n",
    "            threshold_R_sc = 100, threshold_R_oc = 10**8, threshold_MR = 400):\n",
    "    self.progress_text_inter.set('->Working on MR.')\n",
    "\n",
    "    n_to_average = 3\n",
    "    if not os.path.exists(saving_directory + '/MR'):\n",
    "        os.makedirs(saving_directory + '/MR')\n",
    "    df_MR = pd.DataFrame(columns = ['Map Index', 'MR [%]'])\n",
    "    self.progress_bar_inter['maximum'] = num_sensors+1\n",
    "    for index in range(num_sensors+1):\n",
    "        self.progress_bar_inter['value'] = index\n",
    "        self.progress_bar_inter.update()\n",
    "        df_prov = df.loc[df['Map Index'] == index]\n",
    "        if df_prov['Resistance [Ω]'].nsmallest(n_to_average).mean() == 0:\n",
    "            min_R = 0.00000000000001\n",
    "        else:\n",
    "            min_R = df_prov['Resistance [Ω]'].nsmallest(n_to_average).mean()\n",
    "        if df_prov['Resistance [Ω]'].nlargest(n_to_average).mean() == 0:\n",
    "            max_R = 0.00000000000001\n",
    "        else:\n",
    "            max_R= df_prov['Resistance [Ω]'].nlargest(n_to_average).mean()\n",
    "            \n",
    "        MR = (max_R-min_R)*100.0/(min_R)\n",
    "\n",
    "        #Remove too much high MR like > 400\n",
    "        if MR > threshold_MR:\n",
    "            MR = np.nan\n",
    "            \n",
    "         #MR is classified as SC only if the average R is lower then the threshold\n",
    "        if df_prov['Resistance [Ω]'].mean() < threshold_R_sc:\n",
    "            MR = 'SC'\n",
    "        #MR is classified as OC only if the average R is bigger then the threshold\n",
    "        if df_prov['Resistance [Ω]'].mean() > threshold_R_oc:\n",
    "            MR = 'OC'\n",
    "        \n",
    "        df1 = pd.DataFrame([[index, MR]], columns = ['Map Index', 'MR [%]'])\n",
    "        df_MR = df_MR.append(df1, ignore_index=True)\n",
    "    if write_xslx == 1:\n",
    "        df_MR.to_excel(saving_directory + '/MR/MR_' + saving_name + '.xlsx', index = False)\n",
    "    self.progress_bar_inter['value'] = 0\n",
    "    self.progress_bar_inter.update()\n",
    "    return df_MR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R at certain H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_R_at_H(num_sensors, df, saving_name, saving_directory, self, H = 0,\n",
    "                write_xslx = 0, threshold_R_sc = 100, threshold_R_oc = 10**8):\n",
    "    #H=0 by predifinition\n",
    "    self.progress_text_inter.set('->Working on R at field = ' + str(H))\n",
    "    \n",
    "    if not os.path.exists(saving_directory + '/R_at_H' + str(H)):\n",
    "        os.makedirs(saving_directory + '/R_at_H' + str(H))\n",
    "    \n",
    "    df_R_at_H = pd.DataFrame(columns = ['Map Index', 'Applied Field [Oe]',\n",
    "                                        'Resistance [Ω]'])\n",
    "    df_R_at_H_avg = pd.DataFrame(columns = ['Map Index', 'Applied Field [Oe]',\n",
    "                                            'Resistance [Ω]'])\n",
    "    self.progress_bar_inter['maximum'] = num_sensors+1\n",
    "    for index in range(num_sensors+1):\n",
    "        self.progress_bar_inter['value'] = index\n",
    "        self.progress_bar_inter.update()\n",
    "        df_prov = df.loc[df['Map Index'] == index]\n",
    "        df_sort = df_prov.iloc[(df_prov['Applied Field [Oe]'] - H).abs().argsort()[:2]]\n",
    "        df_A = df_sort[['Map Index', 'Applied Field [Oe]', 'Resistance [Ω]']]\n",
    "        \n",
    "        mean_R = df_A['Resistance [Ω]'].mean()\n",
    "\n",
    "        df_R_at_H = df_R_at_H.append(df_A, ignore_index=True)\n",
    "        \n",
    "        if df_prov['Resistance [Ω]'].mean() < threshold_R_sc:\n",
    "            mean_R = 'SC'\n",
    "        if df_prov['Resistance [Ω]'].mean() > threshold_R_oc:\n",
    "            mean_R = 'OC'\n",
    "\n",
    "        new_row = [{'Map Index':int(df_A['Map Index'].mean()),\n",
    "                    'Applied Field [Oe]':df_A['Applied Field [Oe]'].mean(),\n",
    "                    'Resistance [Ω]':mean_R}]\n",
    "        df_R_at_H_avg = df_R_at_H_avg.append(new_row, ignore_index = True, sort = False)\n",
    "    df_R_at_H_avg.to_excel(saving_directory + '/R_at_H' + str(H) + '/' + saving_name +\\\n",
    "                           '_avgs.xlsx', index = False)\n",
    "    if write_xslx == 1:\n",
    "        df_R_at_H.to_excel(saving_directory + '/R_at_H' + str(H) + '/' + saving_name +\\\n",
    "                           '_both.xlsx', index = False)\n",
    "    self.progress_bar_inter['value'] = 0\n",
    "    self.progress_bar_inter.update()\n",
    "    return df_R_at_H, df_R_at_H_avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_Rmin(num_sensors, df, saving_name, saving_directory, self,\n",
    "              threshold_R_sc = 100, threshold_R_oc = 10**8):\n",
    "    self.progress_text_inter.set('->Working on Rmin.')\n",
    "    n_to_average = 3\n",
    "    if not os.path.exists(saving_directory + '/Rmin'):\n",
    "        os.makedirs(saving_directory + '/Rmin')\n",
    "    df_Rmin = pd.DataFrame(columns = ['Map Index', 'Rmin [Ω]'])\n",
    "    self.progress_bar_inter['maximum'] = num_sensors+1\n",
    "    for index in range(num_sensors+1):\n",
    "        self.progress_bar_inter['value'] = index\n",
    "        self.progress_bar_inter.update()\n",
    "        df_prov = df.loc[df['Map Index'] == index]\n",
    "        Rmin = df_prov['Resistance [Ω]'].nsmallest(n_to_average).mean()\n",
    "        threshold_R_sc = float(threshold_R_sc)\n",
    "        threshold_R_oc = float(threshold_R_oc)\n",
    "\n",
    "        if df_prov['Resistance [Ω]'].mean() < threshold_R_sc:\n",
    "            Rmin = 'SC'\n",
    "        if df_prov['Resistance [Ω]'].mean() > threshold_R_oc:\n",
    "            Rmin = 'OC'\n",
    "        \n",
    "        df1 = pd.DataFrame([[index, Rmin]], columns = ['Map Index', 'Rmin [Ω]'])\n",
    "        df_Rmin = df_Rmin.append(df1, ignore_index=True)\n",
    "    df_Rmin.to_excel(saving_directory + '/Rmin/Rmin_' + saving_name + '.xlsx',\n",
    "                     index = False)\n",
    "    self.progress_bar_inter['value'] = 0\n",
    "    self.progress_bar_inter.update()\n",
    "    return df_Rmin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make groups by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split(r'(\\d+)', text) ]\n",
    "\n",
    "\n",
    "def group_by_index(self):\n",
    "    self.progress_text_inter.set('->Grouping figures, progress bar not available.')\n",
    "    stop = 0\n",
    "    owd = os.getcwd()\n",
    "    parent_directory = self.save_directory\n",
    "    subdirectories_list = [x[0] for x in os.walk(parent_directory + '\\\\R_H_curves\\\\SMP')][1:]\n",
    "\n",
    "    all_folders_info = []\n",
    "    all_folders_names_info = []\n",
    "    for subdirectorie in subdirectories_list:\n",
    "        os.chdir(subdirectorie)\n",
    "        index_in_folder = []\n",
    "        names_fig_in_folder = glob.glob('*.png')\n",
    "        names_fig_in_folder.sort(key=natural_keys)\n",
    "        all_folders_names_info.append(names_fig_in_folder)\n",
    "        for image in glob.glob('*.png'):\n",
    "            res = ''.join(filter(lambda i: i.isdigit(), image))\n",
    "            index_in_folder.append(int(res))\n",
    "            os.chdir(owd)\n",
    "        index_in_folder.sort()\n",
    "        all_folders_info.append(index_in_folder)\n",
    "    all_folders_info = [x for x in all_folders_info if x != []]\n",
    "    it = iter(all_folders_info)\n",
    "    the_len = len(next(it))\n",
    "    if not all(len(l) == the_len for l in it):\n",
    "        stop = 1\n",
    "        messagebox.showwarning(title = 'WARNING',\n",
    "                               message = 'Not all indexes of SMP files have the same maximum' +\\\n",
    "                               ' value, it is impossible to group by index!')\n",
    "    if stop == 0:\n",
    "        for i in all_folders_info[0]:\n",
    "            os.makedirs(parent_directory + '/R_H_curves/Index/Index_' + str(i))\n",
    "\n",
    "        for i in range(len(subdirectories_list)):\n",
    "            for j in range(len(all_folders_names_info[i])):\n",
    "                name = subdirectories_list[i].replace(subdirectories_list[i].rsplit('\\\\', 1)[0], '')\n",
    "                shutil.copy(subdirectories_list[i] + '\\\\' + all_folders_names_info[i][j],\n",
    "                            parent_directory + '\\\\R_H_curves\\\\Index\\\\Index_' + str(j) + name +'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_filenames(path_to_dir, suffix = '.csv' ):\n",
    "    filenames = os.listdir(path_to_dir)\n",
    "    filenames.sort(key = natural_keys)\n",
    "    return [filename for filename in filenames if filename.endswith(suffix)]\n",
    "\n",
    "def import_csvs_data(path_to_dir, filenames, self):\n",
    "    self.progress_text_classi.set('->Importing CSVs.')\n",
    "    self.progress_bar_classi['maximum'] = len(filenames) + 1\n",
    "    list_dfs = []\n",
    "    for index in range(len(filenames)):\n",
    "        self.progress_bar_classi['value'] = index\n",
    "        self.progress_bar_classi.update()\n",
    "        filename = filenames[index]\n",
    "        df = pd.read_csv(path_to_dir + '/' + filename,\n",
    "                     usecols = ['Applied Field [Oe]',\n",
    "                                'Resistance [Ω]'])\n",
    "        list_dfs.append(df)\n",
    "    self.progress_bar_classi['value'] = 0\n",
    "    self.progress_bar_classi.update()\n",
    "    self.progress_text_classi.set('')\n",
    "    return list_dfs\n",
    "\n",
    "def resize(arr, lower = -1.0, upper = 1.0):\n",
    "    arr_i = arr.copy()\n",
    "    for n in range(len(arr)):\n",
    "        arr[n] = (upper - lower)/(max(arr_i) - min(arr_i)) * (arr[n] - max(arr_i)) + upper\n",
    "    return arr\n",
    "\n",
    "def linear_inter(list_x, list_y):\n",
    "    list_final_x = []\n",
    "    list_final_y = []\n",
    "    for i in range(len(list_x)-1):\n",
    "        list_final_x.append(list_x[i])\n",
    "        interpol_x_value = (list_x[i] + list_x[i+1])/2.0\n",
    "        list_final_x.append(interpol_x_value)\n",
    "        list_final_y.append(list_y[i])\n",
    "        interpol_y_value = (list_y[i] + list_y[i+1])/2.0\n",
    "        list_final_y.append(interpol_y_value)\n",
    "    list_final_x.append(list_x[-1])\n",
    "    list_final_y.append(list_y[-1])\n",
    "    return list_final_x, list_final_y\n",
    "\n",
    "def upsampling(df_x, df_y, goal_n = 70):\n",
    "    i = 0\n",
    "    list_in_x = df_x.tolist()\n",
    "    list_in_y = df_y.tolist()\n",
    "    while 2*len(list_in_x) <= goal_n :\n",
    "        i+=1\n",
    "        list_x, list_y = linear_inter(list_in_x, list_in_y)\n",
    "        list_in_x = list_x\n",
    "        list_in_y = list_y\n",
    "    \n",
    "    #Deal with times where there are no need to interpolate all points\n",
    "    if 2*len(list_in_x) > goal_n:\n",
    "        n_to_inter = goal_n - len(list_in_x) #number of points to add\n",
    "        mult = int(len(list_in_x)/n_to_inter) #at each multiple of this add a inter\n",
    "        list_new_x = []\n",
    "        list_new_y = []\n",
    "        k=0\n",
    "        for i in range(len(list_in_x)):\n",
    "            list_new_x.append(list_in_x[i])\n",
    "            list_new_y.append(list_in_y[i])\n",
    "            if i % mult == 0 and i != 0 and k < n_to_inter and i+1 < len(list_in_x): #if multiple add inter\n",
    "                #mult #in the first dont # while havent achieved n_to inter\n",
    "                #and do not try to interpolate with value that does not exist\n",
    "                list_new_x.append((list_in_x[i] + list_in_x[i+1])/2.0) #inter value\n",
    "                list_new_y.append((list_in_y[i] + list_in_y[i+1])/2.0) #inter value\n",
    "                k += 1\n",
    "        list_x = list_new_x\n",
    "        list_y = list_new_y\n",
    "    \n",
    "    if goal_n - len(list_x) == 1:\n",
    "        list_x.insert(1, (list_in_x[0] + list_in_x[1])/2.0)\n",
    "        list_y.insert(1, (list_in_y[0] + list_in_y[1])/2.0)\n",
    "\n",
    "    s_out_x = pd.Series(list_x)\n",
    "    s_out_y = pd.Series(list_y)\n",
    "    return s_out_x, s_out_y\n",
    "\n",
    "def downsampling(df_x, df_y, goal_n = 70):\n",
    "    list_in_x = df_x.tolist()\n",
    "    list_in_y = df_y.tolist()\n",
    "    length = float(len(list_in_x))\n",
    "    list_out_x = []\n",
    "    list_out_y = []\n",
    "    for i in range(goal_n):\n",
    "        list_out_x.append(list_in_x[int(ceil(i * length / goal_n))])\n",
    "        list_out_y.append(list_in_y[int(ceil(i * length / goal_n))])\n",
    "    s_out_x = pd.Series(list_out_x)\n",
    "    s_out_y = pd.Series(list_out_y)\n",
    "    return s_out_x, s_out_y\n",
    "\n",
    "def treat_csv_data(list_dfs, self, goal_n_points = 70):\n",
    "    list_dfs_treated = []\n",
    "    list_data_final = []\n",
    "    self.progress_text_classi.set('->Treating CSVs.')\n",
    "    self.progress_bar_classi['maximum'] = len(list_dfs) + 1\n",
    "    for index in range(len(list_dfs)):\n",
    "        self.progress_bar_classi['value'] = index\n",
    "        self.progress_bar_classi.update()\n",
    "        df = list_dfs[index]\n",
    "        if df.shape[0] < goal_n_points:\n",
    "            s_out_app, s_out_resis =  upsampling(df['Applied Field [Oe]'],\n",
    "                                                 df['Resistance [Ω]'],\n",
    "                                                 goal_n = goal_n_points)\n",
    "            df = pd.DataFrame({'Applied Field [Oe]' : s_out_app, 'Resistance [Ω]' : s_out_resis})\n",
    "            df = df.dropna()\n",
    "            \n",
    "        if df.shape[0] > goal_n_points:\n",
    "            df['Applied Field [Oe]'], df['Resistance [Ω]'] = downsampling(df['Applied Field [Oe]'],\n",
    "                                                                          df['Resistance [Ω]'],\n",
    "                                                                          goal_n = goal_n_points)\n",
    "            df = df.dropna()\n",
    "        \n",
    "        df['Resized H [Oe]'] = resize(df['Applied Field [Oe]'])\n",
    "        df['Resized R [Ω]'] = resize(df['Resistance [Ω]'])\n",
    "        list_dfs_treated.append(df.drop(['Applied Field [Oe]', 'Resistance [Ω]'], axis = 1))\n",
    "    for df in list_dfs_treated:\n",
    "        df_final_to_list = df.values.tolist()\n",
    "        list_data_final.append(df_final_to_list)\n",
    "    data_final_array = np.asarray(list_data_final, dtype = np.float32)\n",
    "    data_final_array = data_final_array.reshape(-1, goal_n_points, 2, 1)\n",
    "    data_final_array = data_final_array.astype('float32')\n",
    "    self.progress_bar_classi['value'] = 0\n",
    "    self.progress_bar_classi.update()\n",
    "    self.progress_text_classi.set('')\n",
    "    return data_final_array\n",
    "\n",
    "def predict_proba_to_oneh(predict_prob, self):\n",
    "    encoded_array = np.empty((0, 4), int)\n",
    "    self.progress_text_classi.set('->Making predictions (encoded).')\n",
    "    self.progress_bar_classi['maximum'] = len(predict_prob) + 1\n",
    "    for index in range(len(predict_prob)):\n",
    "        self.progress_bar_classi['value'] = index\n",
    "        self.progress_bar_classi.update()\n",
    "        i = predict_prob[index]\n",
    "        if i[0] > i[1] and i[0] > i[2] and i[0] > i[3]:\n",
    "            l = np.array([[1, 0, 0, 0]])\n",
    "        elif i[1] > i[0] and i[1] > i[2] and i[1] > i[3]:\n",
    "            l = np.array([[0, 1, 0, 0]])\n",
    "        elif i[2] > i[0] and i[2] > i[1] and i[2] > i[3]:\n",
    "            l = np.array([[0, 0, 1, 0]])\n",
    "        elif i[3] > i[0] and i[3] > i[1] and i[3] > i[2]:\n",
    "            l = np.array([[0, 0, 0, 1]])\n",
    "        else:\n",
    "            print('Function must be wrong.')\n",
    "        encoded_array = np.append(encoded_array, l, axis=0)\n",
    "    self.progress_bar_classi['value'] = 0\n",
    "    self.progress_bar_classi.update()\n",
    "    self.progress_text_classi.set('')\n",
    "    return encoded_array\n",
    "\n",
    "def decoder(y_array_encoded, self):\n",
    "    decoded_list = []\n",
    "    self.progress_text_classi.set('->Decoding one-hot predictions.')\n",
    "    self.progress_bar_classi['maximum'] = len(y_array_encoded) + 1\n",
    "    for i in range(len(y_array_encoded)):\n",
    "        self.progress_bar_classi['value'] = i\n",
    "        self.progress_bar_classi.update()\n",
    "        if np.array_equal(y_array_encoded[i], np.array([1, 0, 0, 0])):\n",
    "            l = 'OK'\n",
    "        elif np.array_equal(y_array_encoded[i], np.array([0, 1, 0, 0])):\n",
    "            l = 'M'\n",
    "        elif np.array_equal(y_array_encoded[i], np.array([0, 0, 1, 0])):\n",
    "            l = 'A'\n",
    "        elif np.array_equal(y_array_encoded[i], np.array([0, 0, 0, 1])):\n",
    "            l = 'NOK'\n",
    "        decoded_list.append(l)\n",
    "    decoded_array = np.array(decoded_list)\n",
    "    self.progress_bar_classi['value'] = 0\n",
    "    self.progress_bar_classi.update()\n",
    "    self.progress_text_classi.set('')\n",
    "    return decoded_array\n",
    " \n",
    "def make_predictions_from_path(path_to_csvs, path_to_model, saving_directory,\n",
    "                               predi_excel_name, self):\n",
    "    #saving_directory = path_to_csvs #save the prediction inside the csvs folder\n",
    "    from keras.models import load_model\n",
    "    if not os.path.exists(saving_directory + '/Predictions'): #if folder does not exist\n",
    "        os.makedirs(saving_directory + '/Predictions') #creat it\n",
    "    model = load_model(path_to_model) #loading model\n",
    "    filenames = find_csv_filenames(path_to_csvs) #get all filenames inside directory\n",
    "    df_csvs = import_csvs_data(path_to_csvs, filenames, self) #import all csvs to list of dataframes\n",
    "    data_array = treat_csv_data(df_csvs, self) #up/downsampling and shaping to input layer\n",
    "    y_pred_oneh = predict_proba_to_oneh(model.predict(data_array), self) #making prediction\n",
    "    y_pred_decoded = decoder(y_pred_oneh, self) #decoding prediction from 1h to labels\n",
    "    self.progress_text_classi.set('->Saving predictions.')\n",
    "    df_y_pred = pd.DataFrame({'Map Index': list(range(len(y_pred_decoded))),\n",
    "                              'Prediction': y_pred_decoded,\n",
    "                              'OK' : model.predict(data_array)[:, 0],\n",
    "                              'M' : model.predict(data_array)[:, 1],\n",
    "                              'A' : model.predict(data_array)[:, 2],\n",
    "                              'NOK' : model.predict(data_array)[:, 3]}) #making df\n",
    "    df_y_pred.to_excel(saving_directory + '/Predictions/' + predi_excel_name + '.xlsx',\n",
    "                       index = False) #saving df\n",
    "    self.progress_text_classi.set('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data vizualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_name(path, extension):\n",
    "    owd = os.getcwd()\n",
    "    os.chdir(path)\n",
    "    files_names = glob.glob('*' + extension)\n",
    "    os.chdir(owd)\n",
    "    full_path_list = []\n",
    "    for i in files_names:\n",
    "        full_path_list.append(path + '/' + i)\n",
    "    return full_path_list\n",
    "\n",
    "def get_rele_data(list_map_df, list_meas_df, relevant_init, relevant_final, quantity):\n",
    "    list_rele_df = []\n",
    "    for i in range(len(list_map_df)):\n",
    "        map_df = list_map_df[i]\n",
    "        meas_df = list_meas_df[i]\n",
    "        map_df_relevant = map_df.iloc[relevant_init:relevant_final]\n",
    "        meas_df_relevant = meas_df.iloc[relevant_init:relevant_final]\n",
    "        relevant_df = pd.concat([map_df_relevant, meas_df_relevant['Map Index'],\n",
    "                                 meas_df_relevant[quantity]], axis=1)\n",
    "        list_rele_df.append(relevant_df)\n",
    "    return list_rele_df\n",
    "\n",
    "def get_rele_data_predi(list_map_df, list_meas_df, relevant_init, relevant_final):\n",
    "    list_rele_df = []\n",
    "    for i in range(len(list_map_df)):\n",
    "        map_df = list_map_df[i]\n",
    "        meas_df = list_meas_df[i]\n",
    "        map_df_relevant = map_df.iloc[relevant_init:relevant_final]\n",
    "        meas_df_relevant = meas_df.iloc[relevant_init:relevant_final]\n",
    "        relevant_df = pd.concat([map_df_relevant, meas_df_relevant['Map Index'],\n",
    "                                 meas_df_relevant['Prediction'], meas_df_relevant['OK'],\n",
    "                                 meas_df_relevant['M'], meas_df_relevant['A'],\n",
    "                                 meas_df_relevant['NOK']], axis=1)\n",
    "        list_rele_df.append(relevant_df)\n",
    "    return list_rele_df\n",
    "\n",
    "def change_coordinates_put_name(sns_coors, dfs, names):\n",
    "    '''\n",
    "    Ensures: Returns the dataframe with absolute coordinates\n",
    "    Requires: df = dataframe with measurements and relative coordinates\n",
    "              sns_coor = absolute coordinates of sensor with respect to mask/map\n",
    "    '''\n",
    "    for i in range(len(names)):\n",
    "        df = dfs[i]\n",
    "        sns_coor = sns_coors[i]\n",
    "        name = names[i]\n",
    "        df['x abs'] = df['X'] + sns_coor[0]\n",
    "        df['x abs'] = pd.to_numeric(df['x abs'])\n",
    "        df['y abs'] = df['Y'] + sns_coor[1]\n",
    "        df['y abs'] = pd.to_numeric(df['y abs'])\n",
    "        df['quantity'] = name\n",
    "        dfs[i] = df\n",
    "    return dfs\n",
    "\n",
    "def myround(x, base=10):\n",
    "    #if isinstance(x, str):\n",
    "        \n",
    "    if 0 < x % 10 < 5:\n",
    "        x += 5\n",
    "    return base * round(x/base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_die(n_dies_x, n_dies_y, x_o, y_o, chip_x_dim, chip_y_dim, fig):\n",
    "    \n",
    "    if n_dies_x < 0 and n_dies_y > 0:\n",
    "        for i in range(0, n_dies_x, -1):\n",
    "            for j in range(n_dies_y):\n",
    "                fig.add_shape(type = 'rect', x0 = x_o + (i)*chip_x_dim, y0 = y_o + (j)*chip_y_dim,\n",
    "                              x1 = x_o+ (i+1)*chip_x_dim, y1 = y_o + (j+1)*chip_y_dim,\n",
    "                              line = dict(color = 'Black', width = 2))\n",
    "    elif n_dies_x > 0 and n_dies_y < 0:\n",
    "        for i in range(n_dies_x):\n",
    "            for j in range(0, n_dies_y, -1):\n",
    "                fig.add_shape(type = 'rect', x0 = x_o + (i)*chip_x_dim, y0 = y_o + (j)*chip_y_dim,\n",
    "                              x1 = x_o+ (i+1)*chip_x_dim, y1 = y_o + (j+1)*chip_y_dim,\n",
    "                              line = dict(color = 'Black', width = 2))\n",
    "    elif n_dies_x < 0 and n_dies_y < 0:\n",
    "        for i in range(0, n_dies_x, -1):\n",
    "            for j in range(0, n_dies_y, -1):\n",
    "                fig.add_shape(type = 'rect', x0 = x_o + (i)*chip_x_dim, y0 = y_o + (j)*chip_y_dim,\n",
    "                              x1 = x_o+ (i+1)*chip_x_dim, y1 = y_o + (j+1)*chip_y_dim,\n",
    "                              line = dict(color = 'Black', width = 2))\n",
    "    else:\n",
    "        for i in range(n_dies_x):\n",
    "            for j in range(n_dies_y):\n",
    "                fig.add_shape(type = 'rect', x0 = x_o + (i)*chip_x_dim, y0 = y_o + (j)*chip_y_dim,\n",
    "                              x1 = x_o+ (i+1)*chip_x_dim, y1 = y_o + (j+1)*chip_y_dim,\n",
    "                              line = dict(color = 'Black', width = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def close_window(): \n",
    "    root.destroy()\n",
    "        \n",
    "\n",
    "class App:\n",
    "    def __init__(self, root):\n",
    "        self.filesnames = None\n",
    "        self.save_directory = None\n",
    "        \n",
    "        tabControl = ttk.Notebook(root)\n",
    "        tab_1 = Frame(tabControl)\n",
    "        tabControl.add(tab_1, text = 'Data Processor')\n",
    "\n",
    "        \n",
    "        ###DATA PROCESSOR\n",
    "        frm_data_processor_0 = Frame(tab_1)\n",
    "        \n",
    "        ### Index Column\n",
    "        self.lmap_ind_n = Label(frm_data_processor_0, text='Index Column:')\n",
    "        self.lmap_ind_n.pack(side=TOP, fill='both')\n",
    "        self.map_ind_n = Entry(frm_data_processor_0)\n",
    "        self.map_ind_n.insert(END, ' Input 3 Value')\n",
    "        self.map_ind_n.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ### Field Current Column\n",
    "        self.lfield_c_ind_n = Label(frm_data_processor_0, text='Field Current Column:')\n",
    "        self.lfield_c_ind_n.pack(side=TOP, fill='both')\n",
    "        self.field_c_ind_n = Entry(frm_data_processor_0)\n",
    "        self.field_c_ind_n.insert(END, ' Input 1 Value')\n",
    "        self.field_c_ind_n.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ### Probes Current Column\n",
    "        self.lprobes_c_ind_n = Label(frm_data_processor_0, text='Probes Current Column:')\n",
    "        self.lprobes_c_ind_n.pack(side=TOP, fill='both')\n",
    "        self.probes_c_ind_n = Entry(frm_data_processor_0)\n",
    "        self.probes_c_ind_n.insert(END, ' Input 2 Value')\n",
    "        self.probes_c_ind_n.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ### Probes Voltage Column\n",
    "        self.lprobes_v_ind_n = Label(frm_data_processor_0, text='Probes Voltage Column:')\n",
    "        self.lprobes_v_ind_n.pack(side=TOP, fill='both')\n",
    "        self.probes_v_ind_n = Entry(frm_data_processor_0)\n",
    "        self.probes_v_ind_n.insert(END, ' M4 Volt [V]')\n",
    "        self.probes_v_ind_n.pack(side=TOP, fill='both')\n",
    "        \n",
    "        \n",
    "        #frm_data_processor_0.pack(side=LEFT)\n",
    "        frm_data_processor_0.pack(expand = True, side = LEFT)\n",
    "        frm_data_processor_1 = Frame(tab_1)\n",
    "        \n",
    "        ### Calibration Field\n",
    "        self.lcalib_H = Label(frm_data_processor_1, text='Field calibration [Oe/A]:')\n",
    "        self.lcalib_H.pack(side=TOP, fill='both')\n",
    "        self.calib_H = Entry(frm_data_processor_1)\n",
    "        self.calib_H.insert(END, 961.16)\n",
    "        self.calib_H.pack(side=TOP, fill='both')\n",
    "\n",
    "        ###Select SMP files\n",
    "        self.smp = Button(frm_data_processor_1, text='Select SMPs', fg='black',\n",
    "                          command=self.call_smp_names)\n",
    "        self.smp.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ###Select saving directory\n",
    "        self.saving = Button(frm_data_processor_1, text='Select Saving Directory',\n",
    "                             fg='black', command=self.call_save_directory)\n",
    "        self.saving.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ###Progress Bar SMP\n",
    "        self.lprogress_bar_smp = Label(frm_data_processor_1, text='SMPs Progress:')\n",
    "        self.lprogress_bar_smp.pack(side=TOP, fill='both')\n",
    "        self.progress_bar_smp = ttk.Progressbar(frm_data_processor_1,\n",
    "                                                orient = 'horizontal', length = 5,\n",
    "                                                mode = 'determinate')\n",
    "        self.progress_bar_smp.pack(side = TOP, fill = 'both')\n",
    "        \n",
    "        ###Progress Bar Intermediate\n",
    "        self.lprogress_bar_inter = Label(frm_data_processor_1, text='Current Step:')\n",
    "        self.lprogress_bar_inter.pack(side=TOP, fill='both')\n",
    "        \n",
    "        self.progress_text_inter = StringVar('') \n",
    "        self.progress_text_inter_field = Entry(frm_data_processor_1,\n",
    "                                               textvariable = self.progress_text_inter)\n",
    "        self.progress_text_inter_field.pack(side = TOP, fill = 'both') \n",
    "        \n",
    "        self.progress_bar_inter = ttk.Progressbar(frm_data_processor_1,\n",
    "                                                  orient = 'horizontal',\n",
    "                                                  length = 5, mode = 'determinate')\n",
    "        self.progress_bar_inter.pack(side = TOP, fill = 'both')\n",
    "\n",
    "        #frm_data_processor_1.pack(side=LEFT)\n",
    "        frm_data_processor_1.pack(expand = True, side = LEFT)\n",
    "        frm_data_processor_2 = Frame(tab_1)\n",
    "       \n",
    "        ###BOOLEANS!\n",
    "        \n",
    "        ### Threshold open circuit\n",
    "        self.lHigh_R = Label(frm_data_processor_2, text='OC [R] threshold [\\u03a9]:')\n",
    "        self.lHigh_R.pack(side=TOP, fill='both')\n",
    "        self.High_R = Entry(frm_data_processor_2)\n",
    "        self.High_R.insert(END, 1000000)\n",
    "        self.High_R.pack(side=TOP, fill='both')\n",
    "\n",
    "        ### Threshold short circuit\n",
    "        self.lLow_R = Label(frm_data_processor_2, text='SC [R] threshold [\\u03a9]:')\n",
    "        self.lLow_R.pack(side=TOP, fill='both')\n",
    "        self.Low_R = Entry(frm_data_processor_2)\n",
    "        self.Low_R.insert(END, 100)\n",
    "        self.Low_R.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ###Title\n",
    "        self.Lsecond_row = Label(frm_data_processor_2, text='Select functions:')\n",
    "        self.Lsecond_row.pack(side=TOP, fill='both')\n",
    "        \n",
    "        #frm_RH = Frame(frm_data_processor_2)\n",
    "        ###Make R(H)\n",
    "        self.make_RH_bool = BooleanVar()\n",
    "        self.make_RH_bool.set(True)\n",
    "        self.Lmake_RH_bool = Checkbutton(frm_data_processor_2, text = 'Make R(H) plots',\n",
    "                                         var = self.make_RH_bool) \n",
    "        self.Lmake_RH_bool.pack(side=TOP, anchor = NW)\n",
    "        #self.Lmake_RH_bool.grid(row=1, column=3)\n",
    "        #frm_RH.pack(side = LEFT)\n",
    "        \n",
    "        #frm_MR = Frame(frm_data_processor_2)\n",
    "        ###Make MR\n",
    "        self.make_MR_bool = BooleanVar() \n",
    "        self.make_MR_bool.set(True)\n",
    "        self.Lmake_MR_bool = Checkbutton(frm_data_processor_2, text='Get MR',\n",
    "                                         var = self.make_MR_bool) \n",
    "        self.Lmake_MR_bool.pack(side=TOP, anchor = NW)\n",
    "        #frm_MR.pack(side = LEFT)\n",
    "\n",
    "        ###Make Rmin\n",
    "        self.make_Rmin_bool = BooleanVar() \n",
    "        self.make_Rmin_bool.set(True)\n",
    "        self.Lmake_Rmin_bool = Checkbutton(frm_data_processor_2, text='Get R min',\n",
    "                                           var = self.make_Rmin_bool) \n",
    "        self.Lmake_Rmin_bool.pack(side=TOP, anchor = NW)\n",
    "        \n",
    "        ###Make R AT H\n",
    "        self.make_R_at_H_bool = BooleanVar() \n",
    "        self.make_R_at_H_bool.set(False)\n",
    "        self.Lmake_R_at_H_bool = Checkbutton(frm_data_processor_2, text='Get R at desired field',\n",
    "                                             var = self.make_R_at_H_bool) \n",
    "        self.Lmake_R_at_H_bool.pack(side=TOP, anchor = NW)\n",
    "        \n",
    "        ###Group By Index\n",
    "        self.group_by_index_bool = BooleanVar() \n",
    "        self.group_by_index_bool.set(False)\n",
    "        self.Lgroup_by_index_bool = Checkbutton(frm_data_processor_2, text='Group by Index',\n",
    "                                                var = self.group_by_index_bool) \n",
    "        self.Lgroup_by_index_bool.pack(side=TOP, anchor = NW)\n",
    "        \n",
    "        \n",
    "        #frm_data_processor_2.pack(side=LEFT)\n",
    "        frm_data_processor_2.pack(expand = True, side = LEFT)\n",
    "        frm_data_processor_3 = Frame(tab_1)\n",
    "        \n",
    "        self.Locsc = Label(frm_data_processor_3, text = 'Legend:\\nOC = Open '+\\\n",
    "                           'Circuit\\nSC = Short Circuit')\n",
    "        self.Locsc.pack(side = TOP, fill = 'both', pady = 20)\n",
    "        \n",
    "        ###Submit and run routine\n",
    "        self.number=Button(frm_data_processor_3, text = '!SUBMIT AND RUN ROUTINE!',\n",
    "                           fg = 'black', command = self.call_routine)\n",
    "        self.number.pack(side = TOP, fill = 'both')\n",
    "        \n",
    "        ###Exit program\n",
    "        self.close=Button(frm_data_processor_3, text = 'Quit', fg = 'red', command = close_window)\n",
    "        self.close.pack(side = TOP, fill = 'both')\n",
    "\n",
    "        #frm_data_processor_3.pack(side=LEFT)\n",
    "        frm_data_processor_3.pack(expand = True, side = LEFT)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        tab_2 = Frame(tabControl)\n",
    "        tabControl.add(tab_2, text = 'Sensor Classifier')\n",
    "        \n",
    "        ###SENSOR CLASSIFIER\n",
    "        frm_sensor_classifier_0 = Frame(tab_2)\n",
    " \n",
    "        self.csvs_directory = None\n",
    "        self.save_directory_predictions = None\n",
    "        self.model = None\n",
    "        \n",
    "        ###Select CSVs directory\n",
    "        self.csvs = Button(frm_sensor_classifier_0, text='Select CSVs Directory',\n",
    "                           fg='black', command=self.call_csvs_names)\n",
    "        self.csvs.pack(side=TOP, fill='both')\n",
    "        #self.csvs_directory directory\n",
    "        \n",
    "        ###Select saving directory\n",
    "        self.saving = Button(frm_sensor_classifier_0, text='Select Saving Directory',\n",
    "                             fg='black', command=self.call_save_directory_predictions)\n",
    "        self.saving.pack(side=TOP, fill='both')\n",
    "        #save_directory_predictions directory\n",
    "        \n",
    "        ###Select Model directory\n",
    "        self.model_ask = Button(frm_sensor_classifier_0, text='Select Model Directory',\n",
    "                                fg='black', command=self.call_model)\n",
    "        self.model_ask.pack(side=TOP, fill='both')\n",
    "        #self.csvs_directory directory\n",
    "        \n",
    "        frm_sensor_classifier_0.pack(expand = True, side = LEFT)\n",
    "        frm_sensor_classifier_1 = Frame(tab_2)\n",
    "        \n",
    "        ### Introduce saving name\n",
    "        self.lsaving_name_predi = Label(frm_sensor_classifier_1, text='.xlsx filename:')\n",
    "        self.lsaving_name_predi.pack(side=TOP, fill='both')\n",
    "        self.saving_name_predi = Entry(frm_sensor_classifier_1)\n",
    "        self.saving_name_predi.pack(side=TOP, fill='both')\n",
    "\n",
    "        ###Progress Classification\n",
    "        self.lprogress_bar_classi = Label(frm_sensor_classifier_1, text='Current Step:')\n",
    "        self.lprogress_bar_classi.pack(side=TOP, fill='both')\n",
    "        \n",
    "        self.progress_text_classi = StringVar('') \n",
    "        self.progress_text_classi_field = Entry(frm_sensor_classifier_1,\n",
    "                                                textvariable = self.progress_text_classi)\n",
    "        self.progress_text_classi_field.pack(side = TOP, fill = 'both') \n",
    "        \n",
    "        self.progress_bar_classi = ttk.Progressbar(frm_sensor_classifier_1,\n",
    "                                                   orient = 'horizontal',\n",
    "                                                   length = 5, mode = 'determinate')\n",
    "        self.progress_bar_classi.pack(side = TOP, fill = 'both')\n",
    "\n",
    "        frm_sensor_classifier_1.pack(expand = True, side = LEFT)\n",
    "        frm_sensor_classifier_2 = Frame(tab_2)\n",
    "        \n",
    "        ###Submit and run routine\n",
    "        self.call_routine_predi=Button(frm_sensor_classifier_2,\n",
    "                                       text = '!SUBMIT AND MAKE PREDICTIONS!',\n",
    "                                       fg = 'black',\n",
    "                                       command = self.call_routine_predictions)\n",
    "        self.call_routine_predi.pack(side = TOP, fill = 'both')\n",
    "        \n",
    "        ###Exit program\n",
    "        self.close=Button(frm_sensor_classifier_2, text = 'Quit',\n",
    "                          fg = 'red', command = close_window)\n",
    "        self.close.pack(side = TOP, fill = 'both')\n",
    "\n",
    "        #frm_data_processor_3.pack(side=LEFT)\n",
    "        frm_sensor_classifier_2.pack(expand = True, side = LEFT)\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        tab_3 = Frame(tabControl)\n",
    "        tabControl.add(tab_3, text = 'Data Visualizer')\n",
    "        \n",
    "        \n",
    "        ###DATA Visualizer\n",
    "        frm_data_visualizer_1 = Frame(tab_3)\n",
    "\n",
    "        self.meas_fold_graph = None\n",
    "        self.maps_fold_graph = None\n",
    "        self.saving_dir_graph = None\n",
    "\n",
    "\n",
    "        ### Names for legend\n",
    "        self.llegends = Label(frm_data_visualizer_1, text='Names for the legend:')\n",
    "        self.llegends.pack(side=TOP, fill='both')\n",
    "        self.legends = Entry(frm_data_visualizer_1)\n",
    "        self.legends.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ### Relative coordinates\n",
    "        self.lrelative = Label(frm_data_visualizer_1, text='Relative coordinates:')\n",
    "        self.lrelative.pack(side=TOP, fill='both')\n",
    "        self.relative = Entry(frm_data_visualizer_1)\n",
    "        self.relative.pack(side=TOP, fill='both')        \n",
    "        \n",
    "        ### Plot title\n",
    "        self.ltitle = Label(frm_data_visualizer_1, text='Title for the plot:')\n",
    "        self.ltitle.pack(side=TOP, fill='both')\n",
    "        self.title = Entry(frm_data_visualizer_1)\n",
    "        self.title.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ### Introduce saving name\n",
    "        self.lsaving_names = Label(frm_data_visualizer_1, text='.HTML filename:')\n",
    "        self.lsaving_names.pack(side=TOP, fill='both')\n",
    "        self.saving_names = Entry(frm_data_visualizer_1)\n",
    "        self.saving_names.pack(side=TOP, fill='both')\n",
    "        \n",
    "        frm_data_visualizer_1.pack(expand = True, fill = X, side = LEFT)\n",
    "        frm_data_visualizer_2 = Frame(tab_3)\n",
    "        \n",
    "        ###Select folder with measurement files\n",
    "        self.meas_fold_b = Button(frm_data_visualizer_2, text='Select Measurements Directory',\n",
    "                                  fg='black',\n",
    "                                  command=self.call_meas_fold_graph)\n",
    "        self.meas_fold_b.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ###Select folder with maps files\n",
    "        self.maps_fold_b = Button(frm_data_visualizer_2, text='Select Maps Directory',\n",
    "                                  fg='black', \n",
    "                                  command=self.call_maps_fold_graph)\n",
    "        self.maps_fold_b.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ### Select saving folder\n",
    "        self.saving_fold_b = Button(frm_data_visualizer_2, text = 'Select Saving Directory',\n",
    "                                    fg = 'black',\n",
    "                                    command = self.call_saving_dir_graph)\n",
    "        self.saving_fold_b.pack(side = TOP, fill = 'both')\n",
    "        \n",
    "            \n",
    "        ### Menu selections\n",
    "        self.selection_variable = StringVar(frm_data_visualizer_2)\n",
    "        self.selection_variable.set('Magnetoresistance') # default value\n",
    "\n",
    "        self.lselection_variable = Label(frm_data_visualizer_2, text = 'Select variable to visualize:')\n",
    "        self.lselection_variable.pack(side = TOP, fill = 'both')\n",
    "        self.w = OptionMenu(frm_data_visualizer_2, self.selection_variable, 'Magnetoresistance',\n",
    "                            'Resistance at desired field', 'Minimum Resistance', 'Predictions')\n",
    "        self.w.pack(side=TOP, fill='both')\n",
    "\n",
    "        ###Plot dies\n",
    "        self.plot_die_bool = BooleanVar() \n",
    "        self.plot_die_bool.set(False)\n",
    "        self.Lplot_die_bool = Checkbutton(frm_data_visualizer_2, text = 'Drawn Dies Frames',\n",
    "                                          var = self.plot_die_bool) \n",
    "        self.Lplot_die_bool.pack(side=TOP, fill='both')\n",
    "        \n",
    "        frm_data_visualizer_2.pack(expand = True, fill = X, side = LEFT)\n",
    "        frm_data_visualizer_3 = Frame(tab_3)\n",
    "        \n",
    "        ###Submit and run routine\n",
    "        self.number=Button(frm_data_visualizer_3, text = '!SUBMIT AND RUN ROUTINE!', fg='black',\n",
    "                           command = self.call_routine_graph)\n",
    "        self.number.pack(side=TOP, fill='both')\n",
    "        \n",
    "        ###Exit program\n",
    "        self.close=Button(frm_data_visualizer_3, text = 'Quit', fg = 'red', command = close_window)\n",
    "        self.close.pack(side=TOP, fill='both')\n",
    "        \n",
    "        frm_data_visualizer_3.pack(expand = True, fill = X, side = LEFT)\n",
    "        \n",
    "        tabControl.pack(expan = 1, fill = 'both')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ### Data processor   \n",
    "        \n",
    "    def call_smp_names(self):\n",
    "        self.filesnames = filedialog.askopenfilenames(title = 'Select SMP files',\n",
    "                                                      filetypes = (('SMP Files', '*.smp'),))\n",
    "        messagebox.showinfo(title = 'INFO', message = 'SMP files selected: ' +\\\n",
    "                            str(self.filesnames))\n",
    "        \n",
    "    def call_save_directory(self):\n",
    "        self.save_directory = filedialog.askdirectory(title = 'Select Saving Directory')\n",
    "        messagebox.showinfo(title = 'INFO', message = 'Saving directory selected: ' +\\\n",
    "                            str(self.save_directory))\n",
    "\n",
    "    def call_routine(self):\n",
    "        stop = check_directories(self)\n",
    "        if stop == 0:\n",
    "            smps_directory = self.filesnames\n",
    "            saving_directory = self.save_directory\n",
    "            calib_H = float(self.calib_H.get())\n",
    "            write_xslx_in = 1\n",
    "            \n",
    "            R_max_oc = float(self.High_R.get())\n",
    "            R_min_sc = float(self.Low_R.get())\n",
    "            \n",
    "            # Automatic names\n",
    "            files_names = []\n",
    "            saving_names = []\n",
    "            for i in smps_directory:\n",
    "                files_names.append(i)\n",
    "                prov = i[:-4]\n",
    "                saving_names.append(prov.rsplit('/', 1)[-1])\n",
    "            # End of automatic names\n",
    "            self.progress_bar_smp['maximum'] = len(files_names)\n",
    "            for i in range(len(files_names)):\n",
    "                self.progress_bar_smp['value'] = i\n",
    "                self.progress_bar_smp.update()\n",
    "                file_name = files_names[i]\n",
    "                saving_name = saving_names[i]\n",
    "                df, num_sensors = process_data(file_name, calib_H,\n",
    "                                               map_index_name = str(self.map_ind_n.get()),\n",
    "                                               field_current_name = str(self.field_c_ind_n.get()),\n",
    "                                               probes_current_name = str(self.probes_c_ind_n.get()),\n",
    "                                               probes_voltage_name = str(self.probes_v_ind_n.get()))\n",
    "                if self.make_RH_bool.get() == True:\n",
    "                    make_RH(num_sensors, df, saving_name, saving_directory, self)\n",
    "                if self.make_MR_bool.get() == True:\n",
    "                    make_MR(num_sensors, df, saving_name, saving_directory, self,\n",
    "                            write_xslx = write_xslx_in, threshold_R_oc = R_max_oc,\n",
    "                            threshold_R_sc = R_min_sc)\n",
    "                if self.make_Rmin_bool.get() == True:\n",
    "                    make_Rmin(num_sensors, df, saving_name, saving_directory, self,\n",
    "                              threshold_R_oc = R_max_oc, threshold_R_sc = R_min_sc)\n",
    "                if self.make_R_at_H_bool.get() == True:\n",
    "                    R_at_H = simpledialog.askfloat('R_at_H', 'R at H=')\n",
    "                    make_R_at_H(num_sensors, df, saving_name, saving_directory, self, H = R_at_H,\n",
    "                                write_xslx = write_xslx_in, threshold_R_oc = R_max_oc,\n",
    "                                threshold_R_sc = R_min_sc)\n",
    "            if self.group_by_index_bool.get() == True and self.make_RH_bool.get() == True: #Only available if RH curves are first done\n",
    "                group_by_index(self)\n",
    "            elif self.group_by_index_bool.get() == True and self.make_RH_bool.get() == False:\n",
    "                messagebox.showwarning(title = 'WARNING',\n",
    "                                       message = 'User tried to group by index without' +\\\n",
    "                                       ' making R(H) plots.')\n",
    "\n",
    "            self.filesnames = None\n",
    "            self.save_directory = None\n",
    "            messagebox.showinfo(title = 'INFO', message = 'Computations completed! Check' +\\\n",
    "                                ' the saving folder.')\n",
    "        self.progress_bar_smp['value'] = 0\n",
    "        self.progress_text_inter.set('')\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    ##Classifier\n",
    "    \n",
    "    def call_csvs_names(self):\n",
    "        self.csvs_directory = filedialog.askdirectory(title = 'Select CSVs Directory')\n",
    "        messagebox.showinfo(title = 'INFO', message = 'CSV directory selected: ' +\\\n",
    "                            str(self.csvs_directory))\n",
    "    \n",
    "    def call_save_directory_predictions(self):\n",
    "        self.save_directory_predictions = filedialog.askdirectory(title = 'Select '+\\\n",
    "                                                                  'Saving Directory for predictions')\n",
    "        messagebox.showinfo(title = 'INFO', message = 'Saving directory selected: ' +\\\n",
    "                            str(self.save_directory_predictions))\n",
    "        \n",
    "    def call_model(self):\n",
    "        self.model = filedialog.askdirectory(title = 'Select Directory with model')\n",
    "        messagebox.showinfo(title = 'INFO', message = 'Model folder selected: ' + str(self.model))\n",
    "        \n",
    "    def call_routine_predictions(self):\n",
    "        stop = check_directories_predictions(self)\n",
    "        \n",
    "        if self.saving_name_predi.get() == '':\n",
    "            messagebox.showwarning(title = 'WARNING',\n",
    "                                   message = 'Since you did not give a filename for the excel' +\\\n",
    "                                   ' with predictions, it will be named \".xlsx\".')\n",
    "        \n",
    "        if stop == 0:\n",
    "            csvs_directory = self.csvs_directory\n",
    "            saving_directory = self.save_directory_predictions\n",
    "            model_directory = self.model\n",
    "            predi_excel_name = self.saving_name_predi.get()\n",
    "            \n",
    "            #routine for predictions\n",
    "            make_predictions_from_path(csvs_directory, model_directory, saving_directory,\n",
    "                                       predi_excel_name, self)\n",
    "            \n",
    "            #Erasing data introduced by user so that no errors are commited on next prediction\n",
    "            self.csvs_directory = None\n",
    "            self.save_directory_predictions = None\n",
    "            self.model = None\n",
    "            \n",
    "            messagebox.showinfo(title = 'INFO', message = 'Predictions completed! Check' +\\\n",
    "                                ' the saving folder.')\n",
    "        \n",
    "        \n",
    "        \n",
    "    ##Visualizer\n",
    "    \n",
    "    def call_meas_fold_graph(self):\n",
    "        self.meas_fold_graph = filedialog.askdirectory(title = 'Select Directory with the' +\\\n",
    "                                                       ' Measurement Files')\n",
    "        messagebox.showinfo(title = 'INFO', message = 'Measurement files directory ' +\\\n",
    "                            'selected: ' + str(self.meas_fold_graph))\n",
    "        \n",
    "    def call_maps_fold_graph(self):\n",
    "        self.maps_fold_graph = filedialog.askdirectory(title = 'Select Directory with' +\\\n",
    "                                                       ' the Maps used in the Autoprober')\n",
    "        messagebox.showinfo(title = 'INFO', message = 'Maps directory selected: ' +\\\n",
    "                            str(self.maps_fold_graph))\n",
    "        \n",
    "    def call_saving_dir_graph(self):\n",
    "        self.saving_dir_graph = filedialog.askdirectory(title = 'Select Directory to ' +\\\n",
    "                                                        'save .HTML file')\n",
    "        messagebox.showinfo(title = 'INFO', message = '.HTML file will be saved ' +\\\n",
    "                            'in: ' + str(self.saving_dir_graph))\n",
    "    \n",
    "    def call_routine_graph(self):\n",
    "        stop = 0\n",
    "        plot_title = self.title.get()\n",
    "        files_measurements_dir = self.meas_fold_graph\n",
    "        files_maps_dir = self.maps_fold_graph\n",
    "        names = self.legends.get()\n",
    "        path_saving_graph = self.saving_dir_graph\n",
    "\n",
    "        \n",
    "        if files_measurements_dir == '':\n",
    "            files_measurements_dir = None\n",
    "        if files_maps_dir == '':\n",
    "            files_maps_dir = None\n",
    "        if path_saving_graph == '':\n",
    "            path_saving_graph = None\n",
    "\n",
    "        if files_measurements_dir != None and files_maps_dir != None and path_saving_graph == None:\n",
    "            messagebox.showerror(title='ERROR',\n",
    "                                 message='No Saving Directory was selected, computations' +\\\n",
    "                                 ' interrupted!')\n",
    "            stop = 1\n",
    "        elif files_measurements_dir == None and files_maps_dir != None and path_saving_graph != None:\n",
    "            messagebox.showerror(title='ERROR',\n",
    "                                 message='No Measurements Directory was selected, computations'+\\\n",
    "                                 ' interrupted!')\n",
    "            stop = 1\n",
    "        elif files_measurements_dir != None and files_maps_dir == None and path_saving_graph != None:\n",
    "            messagebox.showerror(title='ERROR',\n",
    "                                 message='No Maps Directory was selected, computations'+\\\n",
    "                                 ' interrupted!')\n",
    "            stop = 1     \n",
    "        elif files_measurements_dir == None and files_maps_dir == None and path_saving_graph != None:\n",
    "            messagebox.showerror(title='ERROR',\n",
    "                                 message='No Measurements and Maps Directory were selected, '+\\\n",
    "                                 'computations interrupted!')\n",
    "            stop = 1\n",
    "        elif files_measurements_dir != None and files_maps_dir == None and path_saving_graph == None:\n",
    "            messagebox.showerror(title='ERROR',\n",
    "                                 message='No Maps and Saving Directory were selected, '+\\\n",
    "                                 'computations interrupted!')\n",
    "            stop = 1\n",
    "        elif files_measurements_dir == None and files_maps_dir != None and path_saving_graph == None:\n",
    "            messagebox.showerror(title='ERROR',\n",
    "                                 message='No Measurements and Saving Directory were selected, '+\\\n",
    "                                 'computations interrupted!')\n",
    "            stop = 1    \n",
    "        elif files_measurements_dir == None and files_maps_dir == None and path_saving_graph == None:\n",
    "            messagebox.showerror(title='ERROR',\n",
    "                                 message='No Measurements, Maps and Saving Directory were selected,' +\\\n",
    "                                 ' computations interrupted!')\n",
    "            stop = 1\n",
    "        elif files_measurements_dir != None and files_maps_dir != None and path_saving_graph != None:\n",
    "            stop = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        str_all_coordinate = self.relative.get()\n",
    "        count = 0\n",
    "        for i in str_all_coordinate:\n",
    "            if i == '(':\n",
    "                count += 1\n",
    "        if count == 0:\n",
    "            stop = 1\n",
    "            messagebox.showerror(title = 'ERROR',\n",
    "                                   message = 'You need to give at least one pair of relative' +\\\n",
    "                                 ' coordinates even if it is \"(0, 0)\".')\n",
    "            list_all_coordinate = []\n",
    "        elif count == 1:\n",
    "            list_all_coordinate = []\n",
    "            list_all_coordinate.append(eval(str_all_coordinate))\n",
    "        else:\n",
    "            list_all_coordinate = list(ast.literal_eval(str_all_coordinate))\n",
    "        \n",
    "        if names == '':\n",
    "            messagebox.showwarning(title = 'WARNING',\n",
    "                                   message = 'Since you did not provide names for datasets the' +\\\n",
    "                                   ' legend will be empty.')\n",
    "        names = names.split(', ')\n",
    "        \n",
    "        if self.saving_names.get() == '':\n",
    "            messagebox.showwarning(title = 'WARNING',\n",
    "                                   message = 'Since you did not give a filename for the .HTML' +\\\n",
    "                                   ' it will be named \".html\".')\n",
    "        if plot_title == '':\n",
    "            messagebox.showwarning(title = 'WARNING',\n",
    "                                   message = 'Since you did not provide a title for the ' +\\\n",
    "                                   'plot it will be empty.')\n",
    "        \n",
    "        if files_maps_dir != None:\n",
    "            files_maps = get_all_name(files_maps_dir, '.xlsx')\n",
    "        else:\n",
    "            files_maps = []\n",
    "        \n",
    "        selected_variable = self.selection_variable.get()\n",
    "        \n",
    "        selection_type = None\n",
    "        if selected_variable == 'Magnetoresistance' and stop == 0:\n",
    "            quantity = 'MR [%]'\n",
    "            selection_type = 'Number'\n",
    "            files_measurements = get_all_name(files_measurements_dir, '.xlsx')\n",
    "        elif selected_variable == 'Resistance at desired field' and stop == 0:\n",
    "            quantity = 'Resistance [Ω]'\n",
    "            selection_type = 'Number'\n",
    "            files_measurements = get_all_name(files_measurements_dir, 'avgs.xlsx')\n",
    "        elif selected_variable == 'Minimum Resistance' and stop == 0:\n",
    "            quantity = 'Rmin [Ω]'\n",
    "            selection_type = 'Number'\n",
    "            files_measurements = get_all_name(files_measurements_dir, '.xlsx')\n",
    "        elif selected_variable == 'Predictions' and stop == 0:\n",
    "            quantity = 'Prediction'\n",
    "            selection_type = 'String'\n",
    "            files_measurements = get_all_name(files_measurements_dir, '.xlsx')\n",
    "            \n",
    "        if stop == 0:\n",
    "            if len(names) != len(files_measurements) or len(names) != len(files_maps) or +\\\n",
    "                len(names) != len(list_all_coordinate):\n",
    "                stop = 1\n",
    "                messagebox.showerror(title='ERROR', message='Check the ammount of data files,' +\\\n",
    "                                     ' maps, legend and relative coordinates, they should' +\\\n",
    "                                     ' be the same!' +\\\n",
    "                                     '\\nNumber of Measurement files given: ' + str(len(files_measurements)) +\\\n",
    "                                     '\\nNumber of Map files given: ' + str(len(files_maps)) +\\\n",
    "                                     '\\nNumber of Legend Names given: ' + str(len(names)) +\\\n",
    "                                     '\\nNumber of relative coordinates given: ' + str(len(list_all_coordinate)))\n",
    "        \n",
    "        if stop == 0:\n",
    "            html_name = path_saving_graph + '/' + self.saving_names.get() + '.html'\n",
    "            fig = go.Figure()\n",
    "            if self.plot_die_bool.get() == True:\n",
    "                self.n_dies_x = simpledialog.askinteger('n_dies_x',\n",
    "                                                        'Enter the number of dies in the x direction:')\n",
    "                self.n_dies_y = simpledialog.askinteger('n_dies_y',\n",
    "                                                        'Enter the number of dies in the y direction:')\n",
    "                self.dies_x_dim = simpledialog.askfloat('dies_x_dimension',\n",
    "                                                              'Enter the dimension of the die in the' +\\\n",
    "                                                        ' x direction:')\n",
    "                self.dies_y_dim = simpledialog.askfloat('dies_y_dimension',\n",
    "                                                              'Enter the dimension of the die in the' +\\\n",
    "                                                        ' y direction:')\n",
    "                if self.n_dies_x != None and self.n_dies_y != None and +\\\n",
    "                    self.dies_x_dim != None and self.dies_y_dim != None:\n",
    "                    plot_die(self.n_dies_x, self.n_dies_y, 0, 0, self.dies_x_dim, self.dies_y_dim, fig)\n",
    "                else:\n",
    "                    messagebox.showwarning(title = 'WARNING', message = 'Rectangular dies will ' +\\\n",
    "                                           'not be plotted because you did not give all the ' +\\\n",
    "                                           'needed parameters!')\n",
    "                self.n_dies_x = None\n",
    "                self.n_dies_y = None\n",
    "                self.dies_x_dim = None\n",
    "                self.dies_y_dim = None\n",
    "                \n",
    "            files_meas_print_g = []\n",
    "            for i in files_measurements:\n",
    "                files_meas_print_g.append(i.split('/')[-1])\n",
    "            \n",
    "            files_maps_print_g = []\n",
    "            for i in files_maps:\n",
    "                files_maps_print_g.append(i.split('/')[-1])\n",
    "                \n",
    "            order_names = messagebox.askquestion(title = 'WARNING', message = 'Are all the files below in the same order?' +\n",
    "                                                 '\\nOrder of Names: ' + str(names)[1:-1] +\n",
    "                                                 '\\nOrder of Relative Coordinates: ' + str(list_all_coordinate)[1:-1] +\n",
    "                                                 '\\nOrder of Measurement files: ' + str(files_meas_print_g)[1:-1] +\n",
    "                                                 '\\nOrder of Map files: ' + str(files_maps_print_g)[1:-1]\n",
    "                                                 , icon = 'warning')\n",
    "            \n",
    "            if order_names == 'yes' and selection_type == 'Number':\n",
    "                all_maps_list = []\n",
    "                all_data_list = []\n",
    "                for i in range(len(files_maps)):\n",
    "                    all_maps_list.append(pd.read_excel(files_maps[i]))\n",
    "                    all_data_list.append(pd.read_excel(files_measurements[i]))\n",
    "\n",
    "                list_rele_df = get_rele_data(all_maps_list, all_data_list, 0, None, quantity)\n",
    "\n",
    "                dfs = change_coordinates_put_name(list_all_coordinate, list_rele_df, names)\n",
    "\n",
    "                all_data = pd.concat(dfs)\n",
    "                data_good = all_data[all_data[quantity].apply(lambda x: isinstance(x, float))]\n",
    "\n",
    "                max_color = myround(data_good[quantity].max(), base=10)\n",
    "                min_color = 0\n",
    "\n",
    "\n",
    "                # Add traces\n",
    "                for i in range(len(names)):\n",
    "                    df = dfs[i]\n",
    "                    df_floats = df[df[quantity].apply(lambda x: isinstance(x, float))]\n",
    "                    data_SC = df[df[quantity] == 'SC']\n",
    "                    data_OC = df[df[quantity] == 'OC']\n",
    "\n",
    "                    fig.add_trace(go.Scatter(x=df_floats['x abs'], y=df_floats['y abs'],\n",
    "                            marker=dict(size=7.5, color = df_floats[quantity], coloraxis = 'coloraxis'),\n",
    "                            mode='markers', name =  df_floats['quantity'].iloc[0],\n",
    "                            text = df_floats['Map Index'],\n",
    "                            hovertemplate = '<br><b>X</b>: %{x}' + \n",
    "                                            '<br><b>Y</b>: %{y}' +\n",
    "                                            '<br><b>Map Index</b>: %{text}<br><b>' + \n",
    "                                            str(quantity) + '</b>: %{marker.color:.1f}', ))\n",
    "\n",
    "                    fig.add_trace(go.Scatter(x=data_SC['x abs'], y=data_SC['y abs'],\n",
    "                            marker=dict(size=7.5, color = 'purple'),\n",
    "                            mode='markers', name = df_floats['quantity'].iloc[0] + ' SC', \n",
    "                            text = data_SC['Map Index'],\n",
    "                            hovertemplate = '<br><b>X</b>: %{x}' +\n",
    "                                            '<br><b>Y</b>: %{y}' +\n",
    "                                            '<br><b>Map Index</b>: %{text}<br><b>' +\n",
    "                                            str(quantity) + '</b>: Shorted', ))\n",
    "\n",
    "                    fig.add_trace(go.Scatter(x=data_OC['x abs'], y=data_OC['y abs'],\n",
    "                             marker=dict(size=7.5, color = 'red'),\n",
    "                             mode='markers', name = df_floats['quantity'].iloc[0] + ' OC',\n",
    "                             text = data_OC['Map Index'],\n",
    "                             hovertemplate = '<br><b>X</b>: %{x}' +\n",
    "                                             '<br><b>Y</b>: %{y}' +\n",
    "                                             '<br><b>Map Index</b>: %{text}<br><b>' +\n",
    "                                             str(quantity) + '</b>: Open', ))\n",
    "\n",
    "\n",
    "                fig.update_xaxes(title_text = 'x - Absolute Position [mm]', showline = True, linewidth = 1,\n",
    "                                 linecolor = 'black', mirror = True, gridcolor = 'LightGrey')\n",
    "                fig.update_yaxes(title_text = 'y - Absolute Position [mm]', showline = True, linewidth = 1,\n",
    "                                 linecolor = 'black', mirror = True, gridcolor = 'LightGrey')\n",
    "                fig.update_layout(yaxis = dict(scaleanchor = 'x', scaleratio = 1),\n",
    "                                  plot_bgcolor = 'rgb(255,255,255)',\n",
    "                                  coloraxis = {'colorscale':'Inferno',\n",
    "                                               'colorscale' : [[0, 'green'],\n",
    "                                                              [0.5, 'rgb(255, 192, 0)'],\n",
    "                                                              [1.0, 'rgb(255, 0, 0)']],\n",
    "                                               'cmin' : min_color, 'cmax' : max_color},\n",
    "                                  coloraxis_colorbar=dict(title = quantity, ticks='outside'),\n",
    "                                  legend=dict(x = -0.3, y = 0.5, title = 'Select Quantities:'),\n",
    "                                  title = plot_title)\n",
    "                fig.write_html(html_name)\n",
    "\n",
    "                self.meas_fold_graph = None\n",
    "                self.maps_fold_graph = None\n",
    "                self.saving_dir_graph = None\n",
    "                selection_type = None\n",
    "                \n",
    "                messagebox.showinfo(title = 'INFO', message = 'Plot completed! Check the saving folder.')\n",
    "                \n",
    "\n",
    "            if order_names == 'yes' and selection_type == 'String':\n",
    "                all_maps_list = []\n",
    "                all_data_list = []\n",
    "                for i in range(len(files_maps)):\n",
    "                    all_maps_list.append(pd.read_excel(files_maps[i]))\n",
    "                    all_data_list.append(pd.read_excel(files_measurements[i]))\n",
    "\n",
    "                list_rele_df = get_rele_data_predi(all_maps_list, all_data_list, 0, None)\n",
    "\n",
    "                dfs = change_coordinates_put_name(list_all_coordinate, list_rele_df, names)\n",
    "\n",
    "                all_data = pd.concat(dfs)\n",
    "\n",
    "                # Add traces\n",
    "                for i in range(len(names)):\n",
    "                    df = dfs[i]\n",
    "                    data_OK = df[df[quantity] == 'OK']\n",
    "                    data_M = df[df[quantity] == 'M']\n",
    "                    data_A = df[df[quantity] == 'A']\n",
    "                    data_NOK = df[df[quantity] == 'NOK']\n",
    "                    \n",
    "                    if not data_OK.empty:\n",
    "                        fig.add_trace(go.Scatter(x=data_OK['x abs'], y=data_OK['y abs'],\n",
    "                                marker=dict(size=7.5, color = 'green'), mode='markers',\n",
    "                                name = data_OK['quantity'].iloc[0] + ' OK',\n",
    "                                customdata = np.stack((data_OK['Map Index'], data_OK['OK'],\n",
    "                                                       data_OK['M'], data_OK['A'], data_OK['NOK']), axis=-1),\n",
    "                                hovertemplate = ('<br><b>X</b>: %{x}'+\\\n",
    "                                                 '<br><b>Y</b>: %{y}'+\\\n",
    "                                                 '<br><b>Map Index</b>: %{customdata[0]}'+\\\n",
    "                                                 '<br><b>Probability OK</b>: %{customdata[1]:.3f}'+\\\n",
    "                                                 '<br><b>Probability M</b>: %{customdata[2]:.3f}'+\\\n",
    "                                                 '<br><b>Probability A</b>: %{customdata[3]:.3f}'+\\\n",
    "                                                 '<br><b>Probability NOK</b>: %{customdata[4]:.3f}<br>')))\n",
    "                    \n",
    "                    if not data_M.empty:\n",
    "                        fig.add_trace(go.Scatter(x=data_M['x abs'], y=data_M['y abs'],\n",
    "                                marker=dict(size=7.5, color = 'yellow'), mode='markers',\n",
    "                                name = data_M['quantity'].iloc[0] + ' M',\n",
    "                                customdata = np.stack((data_M['Map Index'], data_M['OK'],\n",
    "                                                       data_M['M'], data_M['A'], data_M['NOK']), axis=-1),\n",
    "                                hovertemplate = ('<br><b>X</b>: %{x}'+\\\n",
    "                                                 '<br><b>Y</b>: %{y}'+\\\n",
    "                                                 '<br><b>Map Index</b>: %{customdata[0]}'+\\\n",
    "                                                 '<br><b>Probability OK</b>: %{customdata[1]:.3f}'+\\\n",
    "                                                 '<br><b>Probability M</b>: %{customdata[2]:.3f}'+\\\n",
    "                                                 '<br><b>Probability A</b>: %{customdata[3]:.3f}'+\\\n",
    "                                                 '<br><b>Probability NOK</b>: %{customdata[4]:.3f}<br>')))\n",
    "                    if not data_A.empty:\n",
    "                        fig.add_trace(go.Scatter(x=data_A['x abs'], y=data_A['y abs'],\n",
    "                                marker=dict(size=7.5, color = 'orange'), mode='markers',\n",
    "                                name = data_A['quantity'].iloc[0] + ' A',\n",
    "                                customdata = np.stack((data_A['Map Index'], data_A['OK'],\n",
    "                                                       data_A['M'], data_A['A'], data_A['NOK']), axis=-1),\n",
    "                                hovertemplate = ('<br><b>X</b>: %{x}'+\\\n",
    "                                                 '<br><b>Y</b>: %{y}'+\\\n",
    "                                                 '<br><b>Map Index</b>: %{customdata[0]}'+\\\n",
    "                                                 '<br><b>Probability OK</b>: %{customdata[1]:.3f}'+\\\n",
    "                                                 '<br><b>Probability M</b>: %{customdata[2]:.3f}'+\\\n",
    "                                                 '<br><b>Probability A</b>: %{customdata[3]:.3f}'+\\\n",
    "                                                 '<br><b>Probability NOK</b>: %{customdata[4]:.3f}<br>')))\n",
    "                    if not data_NOK.empty:\n",
    "                        fig.add_trace(go.Scatter(x=data_NOK['x abs'], y=data_NOK['y abs'],\n",
    "                                marker=dict(size=7.5, color = 'red'), mode='markers',\n",
    "                                name = data_NOK['quantity'].iloc[0] + ' NOK',\n",
    "                                customdata = np.stack((data_NOK['Map Index'], data_NOK['OK'],\n",
    "                                                       data_NOK['M'], data_NOK['A'], data_NOK['NOK']), axis=-1),\n",
    "                                hovertemplate = ('<br><b>X</b>: %{x}'+\\\n",
    "                                                 '<br><b>Y</b>: %{y}'+\\\n",
    "                                                 '<br><b>Map Index</b>: %{customdata[0]}'+\\\n",
    "                                                 '<br><b>Probability OK</b>: %{customdata[1]:.3f}'+\\\n",
    "                                                 '<br><b>Probability M</b>: %{customdata[2]:.3f}'+\\\n",
    "                                                 '<br><b>Probability A</b>: %{customdata[3]:.3f}'+\\\n",
    "                                                 '<br><b>Probability NOK</b>: %{customdata[4]:.3f}<br>')))\n",
    "\n",
    "\n",
    "                fig.update_xaxes(title_text = 'x - Absolute Position [mm]', showline = True, linewidth = 1,\n",
    "                                 linecolor = 'black', mirror = True, gridcolor = 'LightGrey')\n",
    "                fig.update_yaxes(title_text = 'y - Absolute Position [mm]', showline=True, linewidth=1,\n",
    "                                 linecolor='black', mirror=True, gridcolor='LightGrey')\n",
    "                \n",
    "                fig.update_layout(yaxis = dict(scaleanchor = 'x', scaleratio = 1),\n",
    "                                  plot_bgcolor = 'rgb(255,255,255)',\n",
    "                                  legend = dict(x = -0.3, y = 0.5, title = 'Select Quantities:'),\n",
    "                                  title = plot_title)\n",
    "\n",
    "                fig.write_html(html_name)\n",
    "\n",
    "                self.meas_fold_graph = None\n",
    "                self.maps_fold_graph = None\n",
    "                self.saving_dir_graph = None\n",
    "                selection_type = None\n",
    "                \n",
    "                messagebox.showinfo(title = 'INFO', message = 'Plot completed! Check the saving folder.')\n",
    "\n",
    "\n",
    "root = Tk() # create window\n",
    "root.configure(bg='lightgrey')\n",
    "root.title('AutoProber Data Processor, Sensor Classifier & Visualizer v.4.0')\n",
    "root.wm_iconbitmap('INESC-MN_logo.ico')\n",
    "\n",
    "\n",
    "app = App(root)\n",
    "root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
